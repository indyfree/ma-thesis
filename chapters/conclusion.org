* Conclusion
# NOTE Sec: Setting
Integrating volatile RES into the electricity system imposes challenges on the
electricity grid. In order to ensure grid stability and avoid blackouts,
balancing power is necessary to match electricity supply and demand. Balancing
power can be provided by VPPs that generate or consume energy within a short
period of time and offer these services on the electricity markets
cite:pudjianto07_virtual_power_plant_system_integ. EV fleet operators can
utilize idle vehicles to form VPPs and offer available EV battery capacity as
balancing power to the markets. The fleet can offer balancing services directly
via tender auctions on the balancing market or indirectly via continuous trades
on the intraday market, where participants procure or sell energy to
self-balance their portfolios cite:pape16_are_fundam_enoug. Both markets have
complementary properties in terms of price levels and lead times to delivery,
which motivates the creation of a VPP portfolio to profitably participate in
both markets and extend the business model of the fleet.

# NOTE Sec: Problem
However, there are certain risks associated with this business model extension.
EVs can only be allocated to a VPP portfolio if they are connected to a charging
station and have sufficient free battery capacity available, information which
is unknown to the fleet at the time of market commitment. This uncertainty makes
it difficult for fleet operators to estimate the size of the VPP and calculate
the optimal bidding quantities. Moreover, if fleet operators offer more
balancing power than they can provide, they face high imbalance penalties from
the markets. In order to operate a sustainable business, fleet operators also
need to balance VPP activities with their primary offering, customer mobility.
If the fleet is denying customer rentals to ensure that it can fulfill the
market commitments, it must account for opportunity costs of lost rentals that
may be higher than potential profits of offering the cars' batteries as
balancing power.

In the following chapter, we will summarize the conducted research of this
thesis to address the aforementioned challenges. We will outline the
contribution of this work and present and discuss the main results of our
research. Finally, we will list the limitations of this study and give insights
on further areas of research.

** Contribution
# NOTE Sec: What we have done
#     1. Model (Control mechanism)
#     2. Simulation Platform
#     3. Integrated bidding strategy
#     4. RL Agent that optimizes strategy by determining risk
The core contributions of this thesis are the following: First, we
conceptualized a DSS for controlled EV charging under uncertainty. The DSS
constitutes the core of a business model extension for fleet operators to manage
a VPP portfolio of EV batteries. A controlled charging problem has been
mathematically formulated and a control mechanism introduced that aims to solve
the proposed problem. Second, we developed an event-based simulation platform
that facilitates fleet management research with real-world data. We evaluated
various baseline bidding strategies within the simulation platform and tested
out the behavior of intelligent agents in the context of controlled EV charging.
Third, we proposed a novel integrated bidding strategy that offers balancing
services of a VPP portfolio to multiple electricity markets simultaneously.
Instead of submitting only conservative amounts of battery capacity to a single
market as previous studies did
cite:kahlen17_fleet,kahlen18_elect_vehic_virtual_power_plant_dilem, our proposed
strategy aims to maximize profits by procuring electricity from the multiple
markets to the greatest extent possible without causing imbalances. Fourth, we
proposed the usage of an RL agent that learns to optimize the composition of the
VPP portfolio and the associated risks of bidding on the markets. The agent
dynamically determines risk factors, dependent on the predicted fleet
information and market conditions. Therefore, we formulated an MDP that is
designed for agents to work in previously unknown environments and uncertain
conditions. The RL approach was developed with the focus on real-world
applicability, fast convergence rates, and generalizability. We expect the
proposed approach to work in a variety of different settings, with different
kinds of EVs (e.g., electric bikes), independent of the geographical location of
the fleet.

** Main Findings
# TODO: Double check numbers!
The proposed method was evaluated in a series of experiments with real-world
carsharing data from Car2go in Stuttgart and German electricity market data from
June 2017 until January 2018. The results show that the developed method
improves existing approaches and would increase the gross profits of the fleet
by roughly $75 000\; \eur$ over a 1.5-year period. We found that the integrated
bidding strategy generates 49% - 54% more profits compared to the naive benchmark
strategies. Fleet controllers following the integrated bidding strategy can
mitigate risks and increase profits by exploiting market properties of both
markets. The fleet would also contribute to the integration of RES by providing
around 1500 MWh of balancing power to stabilize the electrical power grid. Since
the inherently uncertain demand patterns of free float carsharing are imposing
additional challenges on securely providing balancing services, better results
are expected with other kinds of EV fleets.

Furthermore, we showed that the proposed RL agent could optimize the integrated
bidding strategy under uncertainty by roughly 12%, missing the optimal result of
a bidding strategy with full information available by only 3%. The agent was
able to successfully estimate the bidding risk, avoid imbalances, and keep lost
rentals to a minimum. Additionally, we tested and compared the performance of
various modern RL algorithms and found that recent advances in deep RL do
improve the robustness and convergence rates in real-world applications, such as
controlled EV charging. Despite these improvements, all tested RL approaches
needed more than 1.5 years of simulation time to learn to avoid imbalance
penalties, which makes an RL approach unsuitable to deploy in unseen fleet
environments without prior training data.

A sensitivity analysis showed that the prediction accuracy of available fleet
charging power has a large impact on the fleet profitability. If the forecasts
about available EVs for VPP use in the future are very uncertain, the RL agent
estimates high bidding risks and can only offer conservative amounts of
balancing power on the markets. Surprisingly, the effect of prediction accuracy
on the total gross profit is more pronounced than the choice of bidding
strategy, which emphasizes the need for highly accurate mobility demand
forecasting algorithms.

Our results compare well to other studies. While
textcite:kahlen17_fleet,kahlen18_elect_vehic_virtual_power_plant_dilem reported
an annual profit increase of up to $121\;\eur$ (163 $) per EV, the experiment
conducted in this thesis yielded an annual increase of $98\; \eur$ per EV from
charging cheaper than the regular industry price. However, in their model,
textcite:kahlen17_fleet,kahlen18_elect_vehic_virtual_power_plant_dilem did not
take imbalance cost into account, which we found to be a determining factor in
the bidding process. When examining an RL approach of EV fleet charging
schedules, textcite:vandael15_reinf_learn_heuris_ev_fleet reported that after 20
to 30 days of training, the algorithm converged to a near-optimal solution. In
our experiments, convergence was reached only after training more than 1.5 years
of simulation time. In contrast to their study, in which the fleet participated
in the day-ahead market, our research focused on balancing markets, which
restrict participants to self-balance their portfolio on other markets and
charge high imbalance penalties instead. Therefore, our proposed RL agent had to
learn never to cause imbalances, which can occur up to one week after the agent
decides on a risk factor for a single bid. Such a long-delayed reward is
traditionally challenging for RL algorithms, which explains the lower
convergence rate of our approach. textcite:chis16_reinf_learn_based_plug_in
investigated an RL approach to reduce charging costs of an individual EV and
reported cost savings of 10% to 50%. While the authors considered a fixed
driving schedule of a single EV, our research considered charging a whole EV
fleet with previously unknown mobility patterns. Despite the additional
uncertainty, we could achieve a cost reduction of charging the fleet by 25%.

** Limitations and Future Work

The conducted research has certain limitations related to the modeled
electricity markets. First, we assume that future price information of the
markets is available to the fleet controller. The controller exploits this
information to optimally place bids that always get accepted by the markets.
Although highly accurate forecasting algorithms exist
cite:avci18_manag_elect_price_model_risk, we eliminated the remaining
uncertainty. In reality, the markets may or may not accept the offered balancing
services, which can compromise the profit of the fleet when it has to charge at
the regular industry price instead.

Second, at a regulatory level, the electricity markets are currently not easily
accessible to single EVs, EV fleets, or small VPPs. For example, the GCRM only
allows actors to participate in the market, which can provide a quantity of at
least 1 MW of balancing power over a 4-hour period. Since it is barely possible
to overcome this constraint with a typical EV fleet consisting of 500 EVs with
unknown rental patterns and the existing charging infrastructure, we ignored the
constraint in our model. We propose changes in the current market design to give
equal access to DER, such as EVs. In order to phase out conventional power
plants and increase the share of renewables in the energy mix, balancing power
needs to be provided from other resources. Instead of 4 to 8-hour segments, the
markets should introduce bidding slots of 15 minutes or less. Moreover, the time
between auction and physical delivery of balancing power should be reduced as
far as possible. Smaller time frames mitigate forecasting errors, which are a
major obstacle for renewable energy generators to efficiently offer their
capacities to the markets. Future research should investigate how these market
design changes and new modifications in the pricing structure (e.g., the German
"Mischpreisverfahren") affect the profitability of using EV batteries as VPPs.

Finally, we see a limitation in the learning rate of the developed RL approach
that concerns the applicability of such an algorithm in a real-world setting
without previously available training data. Future work should test and evaluate
RL control algorithms in physical systems or real appliances in smart
electricity markets. It should be noted that despite the fast-paced development
of RL approaches and its success in many research areas, it is not always the
best solution for all problem types
cite:vazquez-canteli19_reinf_learn_deman_respon. Future research should
investigate how RL approaches in the field of fleet control and VPP optimization
compare against classical stochastic programming methods, for example from
textcite:pandzic13_offer_model_virtual_power_plant. We would also like to
emphasize the need for highly accurate mobility demand forecasting algorithms.
Our results showed that the accuracy of such algorithms has a high influence on
the effectiveness of the fleet control operation.

#+LATEX: \clearpage
