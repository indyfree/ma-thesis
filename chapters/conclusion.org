* Conclusion
# NOTE Sec: Setting
Integrating volatile renewable energy sources into the electricity system
imposes challenges on the electricity grid. In order to ensure grid stability
and avoid blackouts, balancing power is necessary to match electricity supply and
demand. Balancing power can be provided by VPPs that generate or consume energy
within a short period of time and offer these services on the electricity
markets cite:pudjianto07_virtual_power_plant_system_integ. EV fleet operators
can utilize idle vehicles to form VPPs and offer available EV battery capacity
as balancing power to the markets. The fleet can offer balancing services
directly via tender auctions on the balancing market or via continuous trades on
the intraday market, where participants procure or sell energy to self-balance
their portfolios cite:pape16_are_fundam_enoug. Both markets have complementary
properties in terms of price levels and lead times to delivery, which motivates the
creation of a VPP portfolio to profitably participate in both markets and extend
the business model of the fleet.

# NOTE Sec: Problem
However, there are certain risks associated with this business model extension.
EVs can only be allocated to a VPP portfolio if they are connected to a charging
station and have sufficient free battery capacity available, information which
is unknown to the fleet at the time of market commitment. This uncertainty makes
it difficult for fleet operators to estimate the size of the VPP and calculate
the optimal bidding quantities. Moreover, if fleet operators offer more
balancing power than they can provide, they face high imbalance penalties from
the markets. In order to operate a sustainable business, fleet operators also
need to balance VPP activities with their primary offering, customer mobility.
If the fleet is denying customer rentals to ensure that it can fulfill the
market commitments, it must account for opportunity costs of lost rentals that
may be higher than potential profits of offering the cars' batteries as
balancing power.

In the following chapter, we will summarize the conducted research of this
thesis to address the aforementioned challenges. We will outline the
contribution of this work and present and discuss the main results of our
research. Finally, we will list the limitations of this study and give insights
on further areas of research.

** Contribution
# NOTE Sec: What we have done
#     1. Model (Control mechanism)
#     2. Simulation Platform
#     3. Integrated bidding strategy
#     4. RL Agent that optimizes strategy by determining risk
The core contributions of this thesis are the following: First, we
conceptualized a DSS for controlled EV charging under uncertainty. The DSS
constitutes the core of a business model extension for fleet operators to manage
a VPP portfolio of EV batteries. A controlled charging problem has been
mathematically formulated and a control mechanism introduced that aims to solve
the proposed problem. Second, we developed an event-based simulation platform
that facilitates fleet management research with real-world data. We evaluated
various baseline bidding strategies within the simulation platform and tested
out the behavior of intelligent agents in the context of controlled EV charging.
Third, we proposed a novel integrated bidding strategy that offers balancing
services of a VPP portfolio to multiple electricity markets simultaneously.
Instead of submitting only conservative amounts of battery capacity to a single
market as previous studies did
cite:kahlen17_fleet,kahlen18_elect_vehic_virtual_power_plant_dilem, our proposed
strategy aims to maximize profits by procuring electricity from the multiple
markets to the greatest extent possible without causing imbalances. Fourth, we
proposed the usage of an RL agent that learns to optimize the composition of the
VPP portfolio and the associated risks of bidding on the markets. The agent
dynamically determines risk factors, dependent on the predicted fleet
information and market conditions. Therefore, we formulated an MDP that is
designed for agents to work in previously unknown environments and uncertain
conditions. The RL approach was developed with the focus on real-world
applicability, fast convergence rates, and generalizability. We expect the
proposed approach to work in a variety of different settings, with different
kinds of EVs (e.g., electric bikes), independent of the geographical location of
the fleet.

** Main Findings
# TODO: Double check numbers!
The proposed method was evaluated in a series of experiments with real-world
carsharing data from Car2go in Stuttgart and German electricity market data from
June 2017 until January 2018. The results show that the developed method
improves existing approaches and would increase the gross profits of the fleet
by roughly $75 000\; \eur$ over a 1.5 year period. We found that the integrated
bidding strategy generates 49%-54% more profits compared to the naive benchmark
strategies. Fleet controllers following the integrated bidding strategy can
mitigate risks and increase profits by exploiting market properties of both
markets. The fleet would also contribute to the integration of renewable energy
resources by providing around 1400 MWh of balancing power to stabilize the
electrical power grid. Since the inherently uncertain demand patterns of free
float carsharing are imposing additional challenges on securely providing
balancing services, better results are expected with other kinds of EV fleets.

Furthermore, we showed that the proposed RL agent could optimize the integrated
bidding strategy under uncertainty by roughly 12%, missing the optimal result of
a bidding strategy with full information available by only 3%. The agent was
able to successfully estimate the bidding risk, avoid imbalances, and keep lost
rentals to a minimum. Additionally, we tested and compared the performance of
various modern RL algorithms and found that recent advances in deep RL do
improve the robustness and convergence rates in real-world applications, such as
controlled EV charging. Despite these improvements, all RL approaches needed
more than 1.5 years of simulation time to learn to avoid imbalance penalties,
which makes an RL approach unsuitable to deploy in unseen fleet environments
without prior training data.

A sensitivity analysis showed that the prediction accuracy of available fleet
charging power has a large impact on the fleet profitability. If the forecasts
about available EVs for VPP use in the future are very uncertain, the RL agent
estimates high bidding risks and can only offer conservative amounts of
balancing power on the markets. Surprisingly, the effect of prediction accuracy
on the total gross profit increase is more pronounced than the choice of bidding
strategy, which emphasizes the need for highly accurate mobility demand
forecasting algorithms.

Our results compare well to other studies. While
textcite:kahlen17_fleet,kahlen18_elect_vehic_virtual_power_plant_dilem reported
an annual profit increase of up to $121 \eur$ (163$) per EV, the experiment
conducted in this thesis yielded an annual increase of $98 \eur$ per EV from
charging cheaper than the regular industry price. However, in their model,
textcite:kahlen17_fleet,kahlen18_elect_vehic_virtual_power_plant_dilem did not
take imbalance cost into account, which we found to be a determining factor in
the bidding process. When examining an RL approach of EV fleet charging
schedules, textcite:vandael15_reinf_learn_heuris_ev_fleet reported that after 20
to 30 days of training, the algorithm converged to a near-optimal solution. In
our experiments, convergence was reached only after training more than 1.5 years
of simulation time. In contrast to their study, in which the fleet participated
in the day-ahead market, our research focused on balancing markets, which
restrict participants to self-balance their portfolio on other markets charge
high imbalance penalties instead. Therefore, our proposed RL agent had to learn
never to cause imbalances, which can occur up to one week after the agent
decides on a risk factor for a single bid. Such a long-delayed reward is
traditionally challenging for an RL agent, which explains the lower convergence
rate of our approach. textcite:chis16_reinf_learn_based_plug_in investigated an
RL approach to reduce charging costs of an individual EV and reported cost
savings of 10% to 50%. While the authors considered a fixed driving schedule of
a single EV, our research considered charging a whole EV fleet with previously
unknown mobility patterns. Despite the additional uncertainty, we could achieve
a cost reduction of charging the fleet by 25%.

** Limitations and Future Work

The conducted research has certain limitations related to the modeled
electricity markets. First, we assume that future price information of the
markets is available to the fleet controller. The controller exploits this
information to optimally place bids that always get accepted by the markets.
Although highly accurate forecasting algorithms exist
cite:avci18_manag_elect_price_model_risk, we eliminated the remaining
uncertainty. In reality, the markets may or may not accept the offered balancing
services, which can compromise the profit of the fleet when it has to charge at
the regular industry price instead.

Second, at a regulatory level, the electricity markets are currently not easily
accessible to single EVs, EV fleets, or small VPPs. For example, the GCRM only
allows actors to participate in the market, which can provide a quantity of at
least 1 MW of balancing power over a 4-hour period. Since it is barely possible
to overcome this constraint with a typical EV fleet consisting of 500 EVs with
unknown rental patterns and the existing charging infrastructure, it was ignored
in our model. We propose changes in the current market design to give equal
access to distributed energy resources, such as EVs. In order to phase out
conventional power plants and increase the share of renewables in the energy
mix, balancing power needs to be provided from other resources. Instead of 4 to
8-hour segments, the markets should introduce bidding slots of 15 minutes or
less. Moreover, the time between auction and physical delivery of balancing
power should be reduced as far as possible. Smaller time frames mitigate
forecasting errors, which are a major obstacle for renewable energy generators
to efficiently offer their capacities to the markets. Future research should
investigate how these market design changes and new modifications in the pricing
structure (e.g., the German "Mischpreisverfahren") affect the profitability of
using EV VPPs for providing balancing power.

Finally, we see a limitation in the learning rate of the developed RL approach
that concerns the applicability of such an algorithm in a real-world setting
without previously available training data. Future work should test and evaluate
RL control algorithms in physical systems or real appliances in smart
electricity markets. It should be noted that despite the fast-paced development
of RL approaches and its success in many research areas, it is not always the
best solution for all problem types
cite:vazquez-canteli19_reinf_learn_deman_respon. Future research should
investigate how RL approaches in the field of fleet control and VPP optimization
compare against classical stochastic programming methods, for example from
textcite:pandzic13_offer_model_virtual_power_plant. We would also like to
emphasize the need for highly accurate mobility demand forecasting algorithms.
Our results showed that the accuracy of such algorithms has a high influence on
the effectiveness of the fleet control operation.

#+LATEX: \clearpage
