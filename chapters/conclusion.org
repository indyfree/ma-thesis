* Conclusion
# NOTE 5%
# NOTE Sec: Setting
Integrating volatile renewable energy sources into the electricity system
imposes challenges on the electricity grid. In order to ensure grid stability
and avoid blackouts, balancing power is needed to match electricity supply and
demand. Balancing power can be provided by VPPs that generate or consume energy
within a short period of time and offer these services on the electricity
markets cite:pudjianto07_virtual_power_plant_system_integ. EV fleet operators
can utilize idle vehicles to form VPPs and offer available EV battery capacity
as balancing power to the markets. The fleet can offer balancing services
directly via tender auctions on the balancing market or via continuous trades on
the intraday market, where participants procure or sell energy to self-balance
their portfolios cite:pape16_are_fundam_enoug. Both markets have complementary
properties in terms of price levels and lead times to delivery, which motivates the
creation of a VPP portfolio to profitably participate in both markets and extend
the business model of the fleet.

# NOTE Sec: Problem
# NOTE Mention risks? Mention portfolio (optimization)?
However, there are certain risks associated with this business model extension.
EVs can only be allocated to a VPP portfolio if they are connected to a charging
station and have sufficient free battery capacity available, information which
is unknown to the fleet at the time of market commitment. This uncertainty makes
it difficult for fleet operators to estimate the size of the VPP and calculate
the optimal bidding quantities. Moreover, if fleet operators offer more
balancing power than they can provide, they face high imbalance penalties from
the markets. For a sustainable business model fleet operators also need to
balance VPP activities with their primary offering, customer mobility. Denying
customer rentals to ensure that the fleet can fulfill the market commitments,
results in opportunity costs of lost rentals that compromise the profitability
of the fleet.

In the following chapter, we will summarize the conducted research of this
thesis to address the aforementioned challenges. Furthermore, the contribution
of this work is outlined and the main results are presented and discussed.
Finally, we list specific limitations of this study and give insights on further
areas of research.
** Contribution
# NOTE Sec: What we have done
#     1. Model (Control mechanism)
#     2. Simulation Platform
#     3. Integrated bidding strategy
#     4. RL Agent that optimizes strategy by determining risk
The core contributions of this thesis are the following: First, we
conceptualized a DSS for controlled EV charging under uncertainty. The DSS
constitutes the core of a business model extension for fleet operators to manage
a VPP portfolio of EV batteries. A controlled charging problem has been
mathematically formulated and a control mechanism introduced that aims solve the
proposed problem. Second, we developed an event-based simulation platform that
facilitates fleet management research with real-world data. We evaluated various
baseline bidding strategies within the simulation platform and tested out the
behavior of intelligent agents in the context of controlled EV charging. Third,
we proposed a novel integrated bidding strategy that offers balancing services
of a VPP portfolio to multiple electricity markets simultaneously. Instead of
submitting only conservative amounts of battery capacity to a single market,
like previous studies did
cite:kahlen17_fleet,kahlen18_elect_vehic_virtual_power_plant_dilem, our proposed
strategy aims to maximize profits by procuring electricity from the multiple
markets to the greatest extent possible without causing imbalances. Forth, we
proposed the usage of a RL agent that learns to optimize the composition of the
VPP portfolio and the associated risks of bidding on the markets. The agent
dynamically determines risk factors, dependent on available and predicted fleet
information and market conditions. Therefore, we formulated a MDP that is
designed for agents to work in previously unknown environments and uncertain
conditions. The RL approach was developed with the focus on real-world
applicability, fast convergence rates and generalizability. We expect the
proposed approach to work in a variety of different settings, with different
kinds of EVs (e.g., electronic bikes), independent of the geographical location
of the fleet.

# - RL can learn to dynamically adjust bidding quantities by learning risk
#   associated with bidding on each market. (What are the risks?)
# - obtained better results than similar studies in the field. (how much and which?)

# NOTE Sec: What we have found (include key numbers)
# TODO: Double check numbers!
The proposed method was evaluated in a series of expriments with real-world
carsharing data from Car2go in Stuttgart and German electricity market data from
June 2017 until January 2018. The results show that the developed method
improves existing approaches and would increase the gross profits of the fleet
by roughly $74 000\; \eur$ over a 1.5 year period. We found that the integrated
bidding strategy generates 49%-54% more profits, compared to the naive benchmark
strategies. Fleet controllers following the integrated bidding strategy can
mitigate risks and increase profits by exploiting market properties of both
markets. The fleet would also contribute to the integration of renewable energy
resources by providing around 1400 MWh of balancing power to stabilize the
electrical power grid. Since the inherently uncertain demand patterns of free
float carsharing are imposing additional challenges on providing balancing
services, better results are expected with other kinds of EV fleets.

Further, we showed that the proposed RL agent can optimize the integrated
bidding strategy under uncertainty by roughly 12%, missing the optimal result of
a bidding strategy with full information available by only 3%. The agent was
able to successfully estimate the bidding risk, avoid imbalances and keeping
lost rentals to a minimum. Additionally, we tested and compared the performance
of various modern RL algorithms and found that recent advances in deep RL do
improve the robustness and convergence rates in real-world applications. Despite
these improvements, all RL approaches needed more than 1.5 years of simulation
time to learn to avoid imbalance penalties, which makes a RL approach unsuitable
to deploy in unseen fleet environments without prior training data. A
sensitivity analysis showed that the prediction accuracy of available fleet
charging power has large impact on the fleet profitability. If the controllers
predictions are very uncertain, the RL agent estimates high bidding risks and
can only offer conservative amounts of balancing power on the markets.
Surprisingly, the effect of prediction accuracy on the total gross profit
increase is larger than the choice of bidding strategy, which emphasizes the
need for highly accurate mobility demand forecasting algorithms.

Our results compare well to other studies, while
textcite:kahlen17_fleet,kahlen18_elect_vehic_virtual_power_plant_dilem reported
an annual profit increase of up to $121 \eur$ (163$) per EV, the experiment
conducted in this thesis yielded an increase of $111 \eur$ from charging cheaper
than the regular industry price. In their model however, the authors did not
take imbalance cost into account, which we found to be a determining factor in
the bidding process. When examining a RL approach of EV fleet charging
schedules, textcite:vandael15_reinf_learn_heuris_ev_fleet reported that after 20
to 30 days of training, the algorithm converged to a near-optimal solution. In
our experiments, convergence was reached only after training more than 1.5 years
of simulation time. In contrast to their study, which focused the day-ahead
market, our research focused the balancing market, where participants can not
self-balance their portfolio on other markets, but are charged high imbalance
penalties. Therefore, it was a hard requirement for our proposed RL agent to
learn to never cause imbalances. Imbalances can occur up to one week after the
agent decided on a risk factor for a single bid, which makes it challenging to
connect the long-delayed reward signal to the taken action.
textcite:chis16_reinf_learn_based_plug_in investigated a RL approach to reduce
charging costs of an individual EV and reported cost savings of 10% to 50%.
While the authors consider a fixed driving schedule of a single EV, our research
considered charging an EV fleet with previously unknown mobility patterns.
Despite the additional uncertainty, we could achieve a cost reduction of
charging the fleet by 25%.

# NOTE: Mention Exploitation-Exploration dilemma?

# NOTE: Practical Insights/Summary:
# - RL works good
# - Modern Deep RL architectures matter
# - Prediction is more (?) important
# - At the same time the VPP activities have an environmental impact by reducing
#     CO_2 emissions through more efficient use of renewables. By adding more
#     balancing power renewable energy generation does not to be curtailed.
#     Grid needs to get rid of surplus electricity fast

# NOTE Sec: Discuss !!
# - Advantage over forecast like Kahlen: General approach, unseen environments

** Limitations and Future Work

The conducted research has certain limitations related to the modeled
electricity markets. First, we assume that future price information of the
markets are available to the fleet controller. The controller exploits this
information to optimally place bids, resulting that the bids always get accepted
by the market at the best possible price. Although highly accurate forecasting
algorithms exists cite:avci18_manag_elect_price_model_risk, we eliminated the
remaining uncertainty completely. In reality, the markets may or may not accept
the offered balancing services, which can compromise the profit of the fleet
when it has to charge at the regular industry price instead. Second, at
regulation level, the electricity markets are currently not easily accessible to
single EVs, EV fleets or small VPPs. For example, the GCRM only allows
participants which can provide a minimum quantity of 1 MW balancing power over a
4-hour period. Since this is barely possible with a typical EV fleet consisting
of 500 EVs with unknown rental patterns and the present charging infrastructure,
this constraint was ignored in our model. We propose changes in the current
market design to give equal access to DER, like EVs, and small-scale renewable
energy sources. If we want to phase out conventional power plants, and increase
the share of renewables in the energy mix, dependable balancing power needs to
be provided from other resources, such as EVs. The markets should introduce
bidding segments of 15 minutes or less, instead of 4 to 8 hour slots. Moreover,
should the time between auction and physical delivery of balancing power be
reduced as far as possible, to mitigate forecasting errors of available
balancing power, which a major obstacle for renewable energy generators.

Future research should investigate, how these market design changes and
modifications in the pricing structure e.g. the German "Mischpreisverfahren"
introduced in X effects the profitability of using EV VPPs for providing
balancing power.

In terms of the developed model, we detected challenges in the convergence rate
of the online learning method, which compromised the applicability of such an
algorithm in a realistic setting without available training data. The reward
structure of long-delayed imbalances

Future research can also investigate how a RL approach compares against
stochastical programming methods like in
cite:pandzic13_offer_model_virtual_power_plant. It has to be noted that RL is
not always the best solution for all the problems. (See
cite:vazquez-canteli19_reinf_learn_deman_respon conclusion for)

We also like to emphasize the need for highly accurate mobility demand
forcasting algorithms. Without, ... we found...

This result shows that leaving promising room for future research of highly
accurate mobility demand algorithms. Prediction Algorithms improvement,
reference to sensitivity analysis

#+LATEX: \clearpage

