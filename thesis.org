#+TITLE: Reinforcement Learning Portfolio Optimization of Electric Vehicle Virtual Power Plants
#+AUTHOR:Tobias Richter

#+INCLUDE: "./header.org"
#+INCLUDE: "./chapters/introduction.org"
#+INCLUDE: "./chapters/background.org"
#+INCLUDE: "./chapters/empirical-setting.org"

* Model: FleetRL
# NOTE: 20%
# NOTE: Mention VPP more clearly?

# NOTE: Need to reformulate Intro+Following to only balancing
The following chapter will introduce the model of this research. In its essence,
we propose a solution for EV fleet providers to utilize a VPP portfolio to
profitably provide balancing services to the grid on multiple markets. A control
mechanism procures energy from electricity markets, allocates available EVs to
VPPs, and intelligently dispatches EVs to charge the acquired amount of energy.
The model uses a RL agent that learns an optimal bidding strategy by interacting
with the electricity markets and reacts to changing rental demand of the EV
fleet. This chapter is structured as follows: The information assumptions are
listed first, the control mechanism is explained next, and finally the RL
approach is described in detail. For a table of notation refer to Table
ref:table-notation.

# NOTE: Section: Problem Description
We formulate the problem as a /controlled EV charging/ problem. The EV fleet
operator represents the /controller/, which aims to charge the fleet at minimal
costs. First, the controller predicts the amount of energy it can charge in a
given /market period/ $h$. The length of the market period $\Delta h$ and the
market closing time depend on the considered electricity market. Second, the
controller places bids on one or multiple markets to procure the predicted
amount of energy. Lastly, at electricity delivery time, the controller
communicates with the EV fleet to control the charging in real-time. Online EV
/control periods/ $t$ are typically shorter than market periods. In the
empirical case that we consider, the market periods are 15 minutes long, while
the EV control periods last 5 minutes. Nonetheless, the presented approach
generalizes to other period lengths. During each control period, the controller
has to take decisions which individual EVs it should dispatch to charge the
procured amount of electricity. In times of unforeseen rental demand, this
decision implies trading off commitments to the markets with compromising
customer mobility by refusing customer rentals.


#+CAPTION[Table of Notation]: Table of Notation label:table-notation
#+ATTR_LATEX: :environment longtable :align p{0.11\linewidth}|p{0.75\linewidth}|c :placement [hp]
|---------------------------+---------------------------------------------------------------------------+---------|
|---------------------------+---------------------------------------------------------------------------+---------|
| Symbol                    | Description                                                               | Unit    |
|---------------------------+---------------------------------------------------------------------------+---------|
| $t$                       | Control period.                                                           | -       |
| $h$                       | Market period.                                                            | -       |
| $T$                       | Number of control periods in a market period.                             | -       |
| $H$                       | Number of market periods in day.                                          | -       |
| $N_h$                     | Total number of market periods.                                           | -       |
| $\Delta t$                | Length of control period.                                                 | hours   |
| $\Delta h$                | Length of market period.                                                  | hours   |
|---------------------------+---------------------------------------------------------------------------+---------|
| $\Pb{h}$                  | Amount of balancing power offered on the balancing market.                | kW      |
| $\cp{h}$                  | Capacity price offered on the balancing market.                           | $\emw$  |
| $\ep{h}$                  | Energy price offered on the balancing market.                             | $\emwh$ |
| $\ccp{h}$                 | Critical capacity price in market period $h$.                             | $\emw$  |
| $\cep{h}$                 | Critical energy price in market period $h$.                               | $\emwh$ |
|---------------------------+---------------------------------------------------------------------------+---------|
| $\Pi{h}$                  | Amount of power offered for the unit on the intraday market.              | kW      |
| $\up{h}$                  | Unit price offered on the intraday market.                                | $\emwh$ |
| $\cup{h}$                 | Critical unit price in market period $h$.                                 | $\emwh$ |
|---------------------------+---------------------------------------------------------------------------+---------|
| $\Eb{h}$                  | Amount of energy charged from balancing market in market period h.        | MWh     |
| $\Ei{h}$                  | Amount of energy charged from the intraday market in market period h.     | MWh     |
| $p^{i}$                   | Industry tariff                                                           | $\ekwh$ |
|---------------------------+---------------------------------------------------------------------------+---------|
| $\fP{t}$                  | Amount of available fleet charging power in control period $t$.           | kW      |
| $\fPhat{t}$               | Predicted amount of available fleet charging power in control period $t$. | kW      |
|---------------------------+---------------------------------------------------------------------------+---------|
| $\Cb{h}(P)$               | Cost function for procuring electricity from the balancing market.        | $\eur$  |
| $\Ci{h}(P)$               | Cost function for procuring electricity from the intraday market.         | $\eur$  |
| $\oc$                     | Opportunity costs of lost rental of EV $i$ in control period $t$.         | $\eur$  |
| $\beta_h$                 | Imbalance costs in market period $h$.                                     | $\eur$  |
|---------------------------+---------------------------------------------------------------------------+---------|
| $\lb{h}$                  | Balancing market risk factor.                                             | -       |
| $\li{h}$                  | Intraday market risk factor.                                              | -       |
| $\theta_{\lambda}$        | Set of risk factors for all market periods $h\!\in\!\{1,...,N_h\}$.       | -       |
| $\Cf{}(\theta_{\lambda})$ | Cost function for the fleets total costs over all market periods $h$.     | $\eur$  |
| $\Cf{h}$                  | Total accumulated fleet costs until market period $h$.                    | $\eur$  |
|---------------------------+---------------------------------------------------------------------------+---------|
| $i$                       | Electric Vehicle.                                                         | -       |
| $\c$                      | Dummy variable if EV is connected to a charging station.                  | 0/1     |
| $\omega_{i}$              | Amount of electricity stored in EV.                                       | $\kwh$  |
| $\Omega$                  | Maximum battery capacity of EV.                                           | $\kwh$  |
| $\delta$                  | Charging power of EV at the charging station.                             | $\kw$   |
| $\F$                      | Set of all EVs in the fleet                                               | -       |
|---------------------------+---------------------------------------------------------------------------+---------|

** Required Information Assumptions label:sec-model-assumptions
The following information is assumed to be available:

# TODO: Mobility demand --> Charging power
1) The controller is able to forecast the mobility demand of the EV fleet at
   different time-horizons based on historical data. More specifically, it can
   predict the amount of plugged-in EVs and consequently the available charging
   power $P^{fleet}_t$ of the fleet at control period $t$. The prediction's
   accuracy is increasing with shorter time horizons, from uncertain predictions
   one week ahead to very accurate predictions 30 minutes ahead. Past research
   presented successful mobility demand forecast algorithms in the context of
   free-float carsharing
   cite:kahlen18_elect_vehic_virtual_power_plant_dilem,kahlen17_fleet,wagner16_in_free_float.
2) The controller is able to forecast electricity prices of spot and balancing
   markets based on historical data. More specifically, it can estimate the
   critical prices $\ccp{h}$, $\cep{h}$, and $\cup{h}$ for each market period
   with perfect accuracy. The critical prices form an essential piece of
   information for the proposed bidding strategy; bids equal or below the
   critical price will get accepted and result in successful electricity
   procurement. Electricity price forecasting is an extensively studied
   research area, with well-advanced prediction algorithms
   cite:weron14_elect_price_forec,avci18_manag_elect_price_model_risk.
We are confident that taking the above assumptions is viable, assuming available
forecasting information is common practice in the VPP and EV fleet charging
literature, see e.g.:
textcite:brandt17_evaluat_busin_model_vehic_grid_integ,vandael15_reinf_learn_heuris_ev_fleet,mashhour11_biddin_strat_virtual_power_plant_1,tomic07_using_fleet_elect_drive_vehic_grid_suppor,pandzic13_offer_model_virtual_power_plant.

** Control Mechanism
# TODO: Charging power or fleet capacity??

# NOTE: Embed/Mention DSS? What about Smart Charging?
The central control mechanism constitutes the core of this research. It can be
seen as a decision support system that can be deployed at a EV fleet operator to
control the charging its fleet. Figure ref:fig-control-mechanism depicts the
control mechanism, which is divided into three distinct phases:

# TODO:Other figure, with phase timeline?
The first phase, /Bidding Phase I/, takes place just before the closing time of
the balancing market, once every week (e.g., Wednesdays at 3pm at the GCRM). In
this phase, the controller can place bids for every market period $h$ of the
following week on the balancing market. The second phase, /Bidding Phase II/,
takes places in every market period of $\Delta{h}\!=\!15$ minutes. At this
point, the controller has the opportunity to place bids for the market period 30
minutes ahead. By submitting bids 30 minutes ahead of time, the controller
assures that the bid will be matched until the lead time of the market (e.g, 5
minutes on the EPEX Spot Intraday Continuous). The third phase, /Dispatch
Phase/, takes places in every control period of $\Delta{t}\!=\!5$ minutes. In
this phase the controller has to dispatch available EVs to charge the procured
electricity from the markets. This phase involves allocating individual EVs to
the VPP and eventually refusing customer rentals to assure that all commitments
can be fulfilled.

The following chapters will highlight the important parts of the various phases
and provide detailed explanation and mathematical formulations.

#+CAPTION[EV VPP Control Mechanism]: EV VPP Control Mechanism label:fig-control-mechanism
#+ATTR_LATEX: :width 1\linewidth :placement [p]
[[./fig/control_mechanism.png]]

# TODO: Figure:
# - What about regular charging?
# - What about not enough SoC for trip?
# - Allocate costs/profits from charging/trip?

# NOTE: Add timeline week ahead. Place bids week ahead for all following
# market periods m.
# TODO: Mention Market closure times in Background section?
# NOTE: Intro two decision phases

# TODO: Bids always get accepted & activated on Balancing market, mention prices?
# TODO: Generalilzation, lead time, trades always get matched on intraday, prices?
# NOTE: Mention here that we assume to be accepted/activated for balancing market?
# NOTE: Mention here that we bid with the critical prices?

*** Fleet Charging Power Prediction
In a first step, the controller has to predict the available fleet charging
power $\fPhat{h}$ for all market periods $h$ of the next week. The actual
available fleet charging power $\fP{t}$ in a control period $t$ is given by the
number of EVs that are connected to a charging station, with enough free battery
capacity to charge the next control period $t\!+\!1$. As mentioned in the
Chapter ref:sec-model-assumptions, the controller is able to predict the
available fleet charging power $\fPhat{t}$ for all control periods $t$ with
different levels of accuracy dependent on the time horizon of $t$.

When the controller procures electricity from the markets, the fleet has to
charge with the committed charging power during all $T$ control periods of the
market period $h$.
To minimize the risk of not being able to charge the committed amount of energy
during the whole market period, and consequently causing imbalance costs, the
predicted fleet charging power in a market period is defined as the minimal
predicted fleet charging power of all $T$ control periods in a market period.
\begin{equation}
    \fPhat{h} \defeq \min_{n \in \{1, .., T\}} \fPhat{t + n} \text{ ,}
\end{equation}
where $h$ is the market period of interest and $t$ its first control period.

*** Market Decision
In a second step, the controller has to decide from which market it should
procure the desired amount of energy. Therefore, it compares the costs for
charging electricity from the balancing market and the intraday market. The cost
function for charging electricity from the balancing market is defined as follows:
\begin{equation} \label{eq-cost-balancing}
\begin{split}
    \Cb{h}(P) &\defeq -(P\!\times\!10^{-3} \times \ccp{h}) + (\Eb{h} \times \cep{h}) \\
    &= -(P\!\times\!10^{-3} \times \ccp{h}) + (P \frac{\Delta h}{10^{3}} \times \cep{h}) \text{ ,}
\end{split}
\end{equation}
where $P$ (kW) is the amount of offered balancing power. The first term of the
equation corresponds to the compensation the controller retrieves for keeping
the balancing capacity available, while the second term corresponds to the costs
for charging the activated balancing energy $\Eb{h}$ (MWh). Energy is power over
time, hence $\Eb{h}$ can be substituted with $P$ times the market periods length
$\Delta{h}$, divided by the unit conversion from kW to MW. As mentioned in the
Chapter ref:sec-model-assumptions, the critical prices $\ccp{}, \cep{}, \cup{}$
are assumed to be available for all market periods. Note that the critical
energy price $\cep{}\!\in\!\Re$, can also take negative values, resulting in
profits for the fleet, while the critical capacity price $\ccp{}\!\in\! \Re^+_0$
can not take negative values and therefore always results in profits for the
fleet.

The cost function for charging from the intraday market is defined similarly:
\begin{equation}
\begin{split}
    \Ci{h}(P) &\defeq \Ei{h} \times \cup{h} \\
    &= P \frac{\Delta h}{10^{3}}\times \cup{h}
\end{split}
\end{equation}
Again, depending on the market situation, $\cup{}\!\in\!\Re$ can be either
negative or positive, resulting in costs or profits for the fleet. Contrarily to
the balancing market, on the intraday market the fleet does not get compensated
for keeping the charging power available; only the charged energy affects the
costs. If the costs for charging from the balancing market 7 days ahead
$\Cb{h+(7\!\times\!H)}(\fPhat{h+(7\!\times\!H)})$ are higher than the costs of
charging from the intraday market at the same market period $\Ci{h +
(7\!\times\!H)}(\fPhat{h+(7\!\times\!H)})$, the controller does not place bids
on the balancing market.

*** Determining the Bidding Quantity
In a third step, the controller has to take a decision on the amount of energy
it should procure from the markets. Determining the bidding quantity is a
central piece of the controlled charging problem. The bidding quantity
determines the profits that can be made, by charging at a cheaper market price
than the flat industry tariff. In order to maximize its profits, the controller
aims to procure as much electricity as possible from the markets. In order to
optimally place bids on the electricity markets, it needs to balance the risk of
(a) procuring more energy that it can maximally charge and (b) not procuring
enough energy from the market to sufficiently charge the fleet.

In the first case (a), the fleet is facing costs of compromising customer
mobility, or worse, high imbalance penalties from the markets. Renting out EVs
is considerably more profitable than using EVs as a VPP to participate on the
electricity markets. Refusing customer rentals, in order to fulfill market
commitments, induces opportunity costs of lost rentals $\rho$ on the fleet.
Imbalance costs $\beta$ occur, when the fleet can not charge the committed
amount energy at all, even with refusing rentals. In the second case (b), the
fleet also faces opportunity costs of lost rentals when individual EVs do now
have enough SoC for planned trips of arriving customers.

The controller faces additional risks by bidding one week ahead on the balancing
market, in contrast to only 30 minutes ahead on the intraday market, as the
predictions of available charging power are more uncertain with the larger time
horizon. To account for all the mentioned risks, we introduce a /risk factor/
$\lambda \in \Re_{0 \leq \lambda \leq 1}$, where $\lambda = 0$ indicates no
risk, and $\lambda = 1$ indicates a high risk. The controller determines the
bidding quantity $\Pb{h}$ by discounting the predicted available fleet charging
power $\fPhat{h}$ with the possible risk $\lambda_{h}$ of imbalance or
opportunity costs:
\begin{equation} \label{eq-model-pb}
  \Pb{h} \defeq
  \begin{cases}
    0, & \text{if}\ \Cb{h}(\fPhat{h}) \geq \Eb{h}10^3 \times p^{i}\\
    0, & \text{if}\ \Cb{h}(\fPhat{h}) \geq \Ci{h}(\fPhat{h})\\
    \fPhat{h} \times (1\!-\!\lb{h}), & \text{otherwise}
  \end{cases}
\end{equation}
where $h$ is the market period of interest one week ahead. If the controller can
buy electricity at the intraday market at a lower price, it does not place a bid
at the balancing market. If the controller can charge cheaper at the regular
industry tariff $p^{i}$, it does not place a bid either. In all other cases, the
controller submits $\Pb{h}$ to the market.

The bidding quantity for the intraday market $\Pi{h}$ depends on the previously
committed charging power $\Pb{h}$ and the newly predicted charging power
$\fPhat{h}$:
\begin{equation} \label{eq-model-pi}
  \Pi{h} \defeq
  \begin{cases}
    0, & \text{if}\ \Ci{h}(\fPhat{h}\!-\!\Pb{h}) \geq \Ei{h}10^3 \times p^{i}\\
    (\fPhat{h}\!-\!\Pb{h}) \times (1\!-\!\li{h}), & \text{otherwise}
  \end{cases}
\end{equation}
where $h$ is the market period of interest 30 minutes ahead. Note that any
amount of electricity that the controller procured from the balancing market,
does not need to be bought from intraday market for the same market period.
Since the predicted charging power $\fPhat{h}$ is expected to be more
accurate 30 minutes ahead than one week ahead, the controller is able to correct
bidding errors it made in the first decision phase, and optimally charge the
whole EV fleet.

*** Dispatching Electronic Vehicle Charging
In the last step, at electricity delivery time, the EVs have to be assigned to
the VPP and be /dispatched/ to charge. Therefore the controller first needs to
detect how many EVs are eligible to be used as VPP per control period $t$. EVs
are eligible if they (a) are connected to a charging station ($\c$ = 1), and (b)
have enough free battery storage available ($\Omega\!-\!\omega_{i}$) to charge
the next control period. Hence, the VPP is defined as:
\begin{equation}
    V\!P\!P \defeq \{i\in\F \;|\; \c = 1 \vee \Omega\!-\!\omega_{i}\!\geq\!\gamma\Delta{t}\} \text{ ,}
\end{equation}
where $\gamma\Delta{t}$ (kWh) denotes the amount of energy that can be charged
with the charging speed of $\gamma$ (kW) in control period $t$. $\gamma$ is
limited by either the EVs build-in charger, or the charging power of the
connected charging station. In this model we assume $\gamma$ is equal for all
considered EVs and charging stations.

# TODO: How do we known $\oc$?
Remember that the fleet has to provide the committed charging power
$\Pb{h}\!+\!\Pi{h}$ across all control periods $t$ of the market period $h$,
independent of which individual EVs are actually charging the electricity. This
fact allows the controller to dynamically dispatch EVs every control period and
react to unforeseen rental demand. If a customer want to rent out an EV that is
assigned to the VPP, the controller only has to refuse the rental, if no other
EV is available to charge instead. When no replacement EV is available, the
controller has to account for lost rental profits $\oc$. If the VPPs total
amount of available charging power $\vpp{t}\!\times\!\gamma$ is not sufficient to
provide the total market commitments $\Pb{h}\!+\!\Pi{h}$, the fleet gets charged
imbalance costs $\beta_{h}$. Otherwise all the committed energy can be charged
by the VPP.

*** Evaluating the Bidding Risk
The controllers central goal is to choose the risk factors $\lb{h}$, $\li{h}$
for every market period $h$, that minimize the cost of charging, while avoiding
the risks of lost rental profits $\oc$ or imbalance costs $\beta_h$. The total
fleet costs are defined as follows:
\begin{equation} \label{eq-model-fleetcosts}
    \Cf{}(\theta_{\lambda}) \defeq \sum^{N_h}_h
    \bigg[ \Cb{h}(\Pb{h}) + \Ci{h}(\Pi{h}) + \beta_{h}
    + \sum_t^{T} \sum_i^{|\F|} \oc \bigg] \text{ ,}
\end{equation}
where $\theta_{\lambda}\!\in\!\Re_{0 \leq \lambda \leq 1}^{2 \times N_h}$ is the
matrix of the risk factors $\lb{h}$, $\li{h}$ for all considered market periods
$N_h$. $\F$ denotes the set of all EVs $i$ in the fleet and $|\F|$ the fleet
size. The costs for charging $\Cb{h}(\Pb{h})$, $\Ci{h}(\Pi{h})$ are clearly
dependent on the chosen risk factors $\lb{h}$, $\li{h}$ (see Eq.
ref:eq-model-pb, Eq. ref:eq-model-pi). In summary, the problem can be formulated
as minimizing the total costs of the fleet, by choosing the optimal set of risk
factors $\theta_{\lambda}$:
\begin{equation}
\begin{aligned}
    & \underset{\theta_{\lambda}}{\text{minimize}}
    && \Cf{}(\theta_{\lambda}) \\
    & \text{subject to}
    && 0 \leq \lb{h} \leq 1, \; \forall \lb{h} \in \theta_{\lambda}\\
    &&& 0 \leq \li{h} \leq 1, \; \forall \li{h} \in \theta_{\lambda}\\
\end{aligned}
\end{equation}
Solving this optimization problem with common methods like stochastic
programming is a difficult task, assuming that complete information of available
charging power and future electricity market prices is not always available.
Since one goal of this research is to develop a model that can be applied to
previously unknown settings and learn from uncertain environments, as mobility
and electricity markets, we chose to solve the problem with a RL learning
approach that is explained in detail in Chapter ref:sec-model-rl.

*** Example
At 3pm on the 9^{th} of August 2017, the controller enters the first bidding
phase for procuring electricity one week ahead, the market period $h$ =
/16.08.2017 15:00-15:15/. It predicts that at that point in time 250 EVs are connected
to a charging station, resulting in 900kW available fleet charging power
($\fPhat{h}\!=\!900\kw$), given the charging power of 3.6kW per EV. Assuming the
available critical prices $\ccp{h}\!=\!5\emw$, $\cep{h}\!=\!-10\emwh$, and
$\cup{h}\!=\!10\emwh$ for that market period, the controller now evaluates the
cheapest charging option. The flat industry electricity tariff is assumed to be
$p_i\!=\!0.15\ekwh$. The costs for charging with the maximal amount of power
$\fPhat{h}$ from the balancing market ($\Cb{h}(900\kw)\!=\!-6.25\eur$) are less
than charging from the intraday market ($\Ci{h}(900\kw)\!=\!2.25\eur$) or
charging at the industry tariff
($900\kw\!\times\!0.25\text{h}\!\times\!0.15\ekwh\!=\!33.75\eur$). In this
example, by choosing the cheapest option, the balancing market, the fleet
operator will even get compensated for charging its fleet.

# TODO: Really mention assumption of accepted prices again?
In the next step, the controller has to submit bids to the balancing market. The
RL agent determined that the risk of bidding on the balancing market is
$\lb{h}\!=\!0.3$. Consequently, the controller sets the bidding quantity to
$\Pb{h}\!=\!\fPhat{h}\!\times\!(1\!-\!\lb{h})\!=\!900\kw\!\times0.7\!=\!630\kw$ and
submits a bid to the market. Since we are assuming that bids at the critical
price, will always get accepted, the controller procures 630kW from the
balancing market and updates its account with $\Cb{h}(630\kw)\!=\!-4.725\eur$.

One week later, at 2:30pm on the 16^{th} of August 2017, the controller enters
the second bidding phase. With a time horizon of 30 minutes, it predicts less
available fleet charging power of $\fPhat{h}\!=\!810\kw$ for the same market
period /16.08.2017-15:00/. By trading at the intraday market, the controller can
now charge the remaining available EVs with a low risk of procuring more energy
than it can maximally charge. At this point in time, the RL agent determines a
remaining risk of $\li{h}\!=\!0.05$, and sets the bidding quantity to
$\Pi{h}\!=\!(810\kw\!-\!630\kw)\!\times\!(1\!-\!0.05)\!=\!171\kw$. Hence, the
controller procures 171kW from the intraday market and updates its account with
$\Ci{h}(171\kw)\!=\!0.4275\eur$.

At electricity delivery time, the 16^{th} of August 2017 at 3:00pm, the
controller detects 255 available EVs; EVs which are connected to a charging
station and have enough battery capacity left to be charged in the next control
period. It assigns 223 EVs to provide the committed 801kW charging power for the
market period time $\Delta h$ of 15 minutes. During that time, three customers
want to rent out EVs that are allocated to the VPP. The first two rentals are
accepted, because two other EVs are available to charge instead. The third
rental has be to refused, since no EV is remaining as substitution. The
controller has to account for the opportunity costs of the lost rental
$\oc$.

#+BEGIN_SRC python :exports none :var h=15
def bal_cost(p_c, p_e, P):
    return(-(p_c * P * 0.001) + (p_e * P * (h/60) * 0.001))

return(bal_cost(5, -10, 630))
#+END_SRC

#+RESULTS:
: -4.725


#+BEGIN_SRC python :exports none :var h=15
def intraday_cost(p_u, P):
    return((p_u * P * (h/60) * 0.001))

return(intraday_cost(10, 171))
#+END_SRC

#+RESULTS:
: 0.4275

#+BEGIN_SRC python :exports none :var h=15
def industry_costs(p_i, P):
    return((p_i * P * (h/60)) / 100)

return(industry_costs(15, 900))
#+END_SRC

#+RESULTS:
: 33.75

#+BEGIN_SRC python :exports none
def pi(l):
    kw = (810 - 630) * (1 - l)
    return kw

return(pi(0.05))
#+END_SRC

#+RESULTS:
: 171.0

#+BEGIN_SRC python :exports none :var h=15
kw = 630  + 171
return(kw)
#+END_SRC

#+RESULTS:
: 801


# TODO: Do we really need Dispatch Algorithm, if remaining EVs get charged
# regulary?
# --> NO. Only if multiple rentals arrive at the same time and we have to refuse
# some, we could choose to refuse the rentals where EV has LOW SoC, so they get charged

# Assume:
# - Bid maximum capacity price?
# - What about balancing capacity prices? Future work?
# - Bid always multiples of charging capacity, do not consider charging at
#   different speeds

# Other assumptions:
# 1) Bids on balancing market always get accepted (Known critical capacity price $\ccp{}$
# - Operating reserve always gets activated.
# 2) EV fleet charges at a fixed industry tariff otherwise
# 3) Balancing capacity is provided for a market period $h$. Within the market
#    period $h$, it is possible to provide the capacity with different EVs,
#    changing in control periods $t$. Customers arrive in $t$ intervals.


# - Fleet capacity prediction made on non-simulated real-world SoC (w/o smart charging)?
# - Fleet capacity predictions with simulated data?
#   - Provide difference levels & descriptive statistics?


# NOTE: Word as profit-maximizing bidding strategy
# Assumptions:
#   - EV fleet is price taker, it is lacking the market share to influence prices
#     - $\rightarrow$ Use existing prices, w/o simulating influence of bids.
#   - Relax minimum bidding assumption of 1MW to no limit. Sensitivity analysis
#     with 100kw and 500kw in evaluation
#   - Controller always bids at an optimal price.
#   - Assume always the perfect bid: Upper-bound evaluation, with critical prices
#   - Figure about prices developments over the day? Compare balancing & intraday?

# # FIXME: Citation brandt
# Furthermore, we assume the aggregator is a price-taker. In case of limited size
# purchase orders, an aggregator will naturally have a price-taker position.

# # FIXME: Citatation from kahlen
# The fleet controller offers bids and asks for every time interval. These offers
# contain both a quantity and a reservation price, which depends on the state of
# charge of the EV storage, as well as on the battery costs. However, the market
# may or may not accept these offers depending on the composition of the offer
# prices from the fleet owner and other market participants. The market auction
# mechanism ultimately decides when EVs will charge and discharge.
** Reinforcement Learning Approach label:sec-model-rl
# NOTE: RL Learning only technical, everything else in before? - Yes
In the following chapter the developed RL approach is outlined. First, we define
the charging problem as a MDP, and second, the used learning algorithm is
explained.

Remember that the goal of the controlled charging problem is to choose a set of
risk factors $\theta_{\lambda}$ that minimize the fleets total costs across all
market periods. The controller is able to influence the charging costs, by
setting the risk factors $\li{h}$, $\lb{h}$, which determine the bidding
quantities $\Pb{h}$, $\Pi{h}$ that the controller submits to the balancing and
intraday market. The RL agent decides on the risk factors (i.e., takes an
action) based on the observed state $\S$ every timestep. Bids are submitted
every market period $h$, thus the /timestep/ (also called iteration) of the RL
problem is set to $h$, with a length of $\Delta{h}$. The optimal set of risk
factors are learned by the RL agent through estimating a policy $\pi(a|s)$ that
maps every state $s\in\S$ to an action $a\in\A$.
*** Markov Decision Process Definition

MDPs are defined by the state space $\S$, the action space $\A$, a set of reward
signals $\R$ and the state-transition probabilities $p(s'|a,s)$. When
$p(s'|a,s)$ is unknown, as it is in our case, it is possible to use a
/model-free/ approach (see Chapter ref:sec-td-learning). The state space
compromises the observed information the agent uses to decide on the action it
is going to take. We observed the following factors that are associated with the
bidding risk:
1) The bidding period's time of the day

   In times of volatile customer rental demand (e.g., rush hour), the
   uncertainty on the guaranteed amount of available EVs increases. Bidding for
   these periods involves more risk of not being able to fulfill market
   commitments.
2) The current and estimated future size of the VPP

   Large VPPs benefit from the /risk-pooling/ effect cite:kahlen17_fleet.
   Intuitively that means, larger VPPs are exposed to smaller risks: They have
   an increased probability that "lost" charging power, due to unforeseen
   rentals, can be substituted by the other EVs of the VPP.
Since forecasts of available charging power are already available, we define the
predicted VPP size $\vpphat{h}$ as the as the necessary amount of EVs to
provide the predicted charging power $\fPhat{}$ in time period $h$:
\begin{equation}
    \vpphat{h} \defeq \left\lceil\frac{\fPhat{h}}{\gamma}\right\rceil \text{ ,}
\end{equation}
where $\gamma$ is the charging power per EV. The state space is then defined as
the set of all valid values of the elements of the following tuple:
\begin{equation}
    \S \defeq \left\langle t(h), \vpp{h}, \vpphat{h+2}, \vpphat{h+(7\!\times\!H)}\right\rangle \text{ ,}
\end{equation}
where:
- $t(h)$ is the current daytime in hours, with discrete values in the range
  $\big[0,\;23\big] \in \Ne$.
- $|VPP|_t$ is the current VPP size, with discrete values in the range
  $\big[0,\;|\F|\big] \in \Ne$.
- $\vpphat{h+2}$ is the predicted VPP size 30 minutes ahead, with discrete values in the range
  $\big[0,\;|\F|\big] \in \Ne$.
- $\vpphat{h+(7\!\times\!H)}$ is the predicted VPP size 7 days ahead, with discrete
  values in the range $\big[0,\;|\F|\big] \in \Ne$.
The state space encompasses $|\F|^3\!\times\!24$ states. Assuming a fleet size
$|\F|$ of 500 EVs that are $3\!\times\!10^9$ states.
#+BEGIN_SRC python :exports none
import math
return(24 * math.pow(500,3))
#+END_SRC

#+RESULTS:
: 3000000000.0
The agent's action is choosing the risk that is associated with bidding on the
electricity markets each market period $h$. Hence, the action space is
constituted by all valid values of the risk factors $\lb{h},\li{h}$:
\begin{equation}
    \A \defeq \left\{\lb{h},\li{h} \in \Re_{0 \leq \lambda \leq 1} \right\} \text{ ,}
\end{equation}
where:
- $\lb{h}$ is the risk factor for bidding on the balancing market 7 days ahead,
  with discrete values in the range $\big[0,1\big]$ in 0.05 increments.
- $\li{h}$ is the risk factor for bidding on the intraday market 30 minutes
  ahead, with discrete values in the range $\big[0,1\big]$ in 0.05 increments.
The action space encompasses $20^2 = 400$ actions. The state space and action
space were consciously discretized to facilitate faster convergence rates of the
learning process. Convergence with continuous spaces is theoretically feasible
with current function approximation methods, but is computational more complex
cite:sutton18_reinf.

# NOTE: Reward structure, possibilities
The reward signal is defined as the total fleet costs that occurred in the last
timestep:
\begin{equation}
    R_{h+1} = \Cf{h} - \Cf{h-1} \text{ ,}
\end{equation}
where $\Cf{h}$ are the total accumulated fleet costs until market period $t$.
The agent's actions determined the bidding quantities, which led to profits from
charging cheaper than the industry tariff, and possibly caused imbalance or lost
rental costs. See \eqref{eq-model-fleetcosts} for a formulation the cost
function. The occurred costs associated with the action are presented to the
agent in the form of a positive or a negative reward signal. The particular
challenge in the proposed RL problem is the very long delayed reward. Choosing
an action $a$ in timestep $h$ will have an effect on the reward 672 timesteps ($7
\text{ days}\!\times\!24\text{ hours}\!\times\!4\text{ market periods of 15 minutes}$) later, due to the
week ahead commitments on the balancing market.

#+BEGIN_SRC python :exports none
return(7 * 24 * 4)
#+END_SRC

#+RESULTS:
: 672

*** Learning Algorithm
We propose to solve the RL problem layed out in the previous chapter with the
Double Deep Q-Network (DDQN) algorithm
cite:hasselt16_deep_reinf_learn_doubl_q_learn. DDQN is a state-of-the-art
model-free RL algorithm, that combines the popular Deep Q-Network (DQN)
algorithm, originally proposed by
textcite:mnih15_human_level_contr_throug_deep_reinf_learn with Double Q-Learning
cite:hasselt16_deep_reinf_learn_doubl_q_learn. DDQN have shown to reduce DQN's
overoptimistic action-values, resulting in more stable and reliable learning
results. Combined with a dueling network architecture, proposed by
textcite:wang15_duelin_networ_archit_deep_reinf_learn, this approach outperforms
existing approaches for deep RL. The dueling network architecture, leads to
faster convergence rates in control problems with large action spaces than a
traditional single stream approach. This is especially beneficial for our
proposed controlled fleet charging problem, as the action space, with 400
possible actions, is comparably large in comparison to classical control
problems.

The dueling architecture (see Figure ref:fig-model-dueling, bottom) has consists two
streams to separately estimate the state-value and the action advantages.
- Shared features?
- ...


- Used NN architecture?

#+CAPTION[DDQN Dueling Network Architecture]: The DDQN dueling network architecture cite:wang15_duelin_networ_archit_deep_reinf_learn label:fig-model-dueling
#+ATTR_LATEX: :width 0.95\linewidth
[[./fig/ddqn.pdf]]

The RL agent was implemented in Python 3.6, and used the library Keras
(https://keras.io/). Keras is "a high-level neural networks API, [...] capable
of running on top of TensorFlow [...] with a focus on enabling fast
experimentation".

- OpenAi Gym?
  - Hardware: Google Colab
    - GPU: Nvidia Tesla K80 , 2880 x 2 CUDA cores, 12GB GDDR5 VRAM
    - CPU: Intel(R) Xeon(R) CPU @ 2.30GHz (1 core, 2 threads), 45MB Cache
    - RAM: ~12.6 GB Available
  - Training:
    - Time
    - Hyperparameters? - In results or here?

* Simulation Platform: FleetSim
# NOTE: 5%
# NOTE: Cite Ketter PowerTac (and Competitive Benchmarking)
- Simulation Platform to allow evaluating the performance of intelligent agents
  in smart charging/balancing the grid of EV fleets. Allows to test out bidding strategies
  and control mechanisms in a realistic EV fleet setting.
- Real life comparison graph: 10%.
** Event-based Simulation
- Not only t+1
- Event e.g. denying rental, charge/little charge/no-charge has effects for the
  whole simulation
- Simpy
- Python
** Architecture / Components
#+CAPTION[FleetSim Architecture]: Architecture of FleetSim label:fig-fleetsim
#+ATTR_LATEX: :width 1\linewidth
[[./fig/simulation_platform.png]]

** Modular Expandability
- Plug-in different Market designs
- Use different real-world data
- Change Fleet parameters
- Develop new strategy
-
# #+LATEX: \clearpage
* Results
# NOTE: 15%
# NOTE: What about infer charging stations?
# - Run regular with charging stations
# - Run strategy with no/less regular charging
# NOTE: Also include overview graphs, of charging, prices, available capacity,
# car2go trips, etc..
# NOTE: Include overview graphs of different RL methods over time
# NOTE: List Simulation params in a table: Car Capacity etc..
# NOTE: Make decision outcome results table over one-year period like kahlen
# NOTE: Include EUR/MWh provided!
** Simulation Settings
# NOTE: Include Graph of electricity prices
- Results heavily dependent on industry charging price, since on average the
  balancing prices are 50% cheaper, and intraday 30% cheaper.
- BMWi. (n.d.). Prices of electricity for the industry in Germany from 2008 to
  2017 (in euro cents per kilowatt hour). In Statista - The Statistics Portal.
  Retrieved March 18, 2019, from
  https://www.statista.com/statistics/595803/electricity-industry-price-germany/.
** FleetRL
- long-delayed rewards make RL hard (!?)
- Compare RL Algos eg. Q-learning vs DDQN --> deep learning makes difference in
  practice for complex system
** Sensitivity Analysis
# NOTE: Prediction Accuracy of available EV capacity
# NOTE: Balancing accuracy always lower than intraday! Otherwise no sense
# NOTE: Do predict electricity prices?
- Prediction Accuracy
# NOTE: Fastchargers
# NOTE: Car batteries
- Charging infrastructure
* Conclusion
# NOTE 5%
** Contribution
- Compare to most simular studies:
cite:kahlen18_elect_vehic_virtual_power_plant_dilem,vandael15_reinf_learn_heuris_ev_fleet etc..
- Business model for EV fleet owners with better results than previous studies
- Environmental impact by providing balancing power
- Decision Support System for controlled EV charging from multiple markets
- RL Algorithm that is designed to work in previously unknown environments and
  thus suited to deploy in real life settings of all kinds of EV fleets in all
  kinds of cities. E.g. scooters also?
- Event-based Simulation Platform to evaluate bidding strategies and RL agents,
  facilitate research

** Limitations
- Model:
  - Bidding Mechanism: one week ahead, always accepted
  - Policy & Regulation: EVs not allowed to provide balancing power, minimum
    bidding quantities 1MW.
  - Markets: Fleet is a price-taker, what about larger fleets? Simulate market influence
- RL: See cite:vazquez-canteli19_reinf_learn_deman_respon conclusion for
  limitations.
** Future Research
- Model: Current market design, i.e. daily w/ 4h slots. German "Mischpreisverfahren"
- RL: Long-delayed rewards, different reward structure, memory based

#+LATEX: \clearpage
bibliography:~/uni/ma-thesis/bibliography/references.bib
bibliographystyle:apacite

* Footnotes

